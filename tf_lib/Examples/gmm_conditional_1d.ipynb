{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GMM\n",
    "Created by: Daniel L. Marino (marinodl@vcu.edu)\n",
    "\n",
    "Description: gaussian mixture model implementation on tensorflow, the objective is a conditional probabilistic distribution. \n",
    "\n",
    "This file serves as a visual test for the gmm extension modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from twodlearn.tf_lib.datasets.generic import Datasets\n",
    "from twodlearn.tf_lib.GMM import *\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def gmm_sampling(mu, sigma, w, n_samples=1):\n",
    "    # generates random vectors, sampled from a gausian mixture model\n",
    "    #  \n",
    "    #     - mu: 3d tensor containing the means for the gaussians.\n",
    "    #           the \"depth\" dimention (3rd) is used to index the\n",
    "    #           gaussians.    [ kernel_id, dim]\n",
    "    #     - sigma: 3d tensor containing the covariance matrix of the\n",
    "    #              gaussians. [ kernel_id, dim] for diagonal matrices\n",
    "    #     - w: vector in form of a 3d tensor containing the weights\n",
    "    #          for each one of the gaussians, they have to sum one. \n",
    "    #          [kernel_id]\n",
    "    n_kernels = mu.shape[0]\n",
    "    n_dim = mu.shape[1]\n",
    "    \n",
    "    # random sample the kernel from which the output samples are going\n",
    "    # to be drawn\n",
    "    kernel_id= np.argmax(np.random.multinomial(1, w, size=[n_samples]), axis=1 )\n",
    "    \n",
    "    out = np.zeros([n_samples, n_dim])\n",
    "    for i in range(n_samples):\n",
    "        out[i,:]= np.random.multivariate_normal(mu[kernel_id[i],:], np.diag(sigma[kernel_id[i],:])) # if diagonal\n",
    "    \n",
    "    return out;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1000000,)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 1000000\n",
    "\n",
    "sigma_r = 1.0*np.exp(-0.005*np.linspace(0, 1000, n_samples))\n",
    "w_r = [1]  # has to sum to one\n",
    "\n",
    "aux_x= np.linspace(0, 6, n_samples)\n",
    "aux_y= np.linspace(0, 6, n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    aux_y[i] = np.random.normal(np.sin( aux_x[i] ), sigma_r[i])\n",
    "\n",
    "# build the dataset\n",
    "data = Datasets(aux_x, aux_y)\n",
    "data.normalize()\n",
    "print('Data shape: ', data.train.x.shape)\n",
    "\n",
    "# plot\n",
    "#plt.plot(data.train.x, data.train.y, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20000119997e-05\n"
     ]
    }
   ],
   "source": [
    "print(np.sin(aux_x[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#config = tf.ConfigProto( device_count = {'GPU': 0} )\n",
    "#sess = tf.InteractiveSession(config = config)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_inputs = 1\n",
    "n_outputs = 1\n",
    "n_hidden= [4]\n",
    "n_kernels = 1\n",
    "\n",
    "\n",
    "gmm_model = GmmMlpModel( n_inputs, n_outputs, n_hidden, n_kernels, \n",
    "                             afunction= tf.sigmoid, diagonal= True, method='tdl')\n",
    "\n",
    "train_model= gmm_model.setup(n_samples)\n",
    "    \n",
    "# Optimizer.\n",
    "optimizer = tf.train.AdamOptimizer(0.002).minimize(train_model.loss) #0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu shape: (1000000, 1, 1)\n",
      "sigma shape: (1000000, 1, 1)\n",
      "w shape: (1000000, 1)\n",
      "out shape: <unknown>\n",
      "loss shape: <unknown>\n"
     ]
    }
   ],
   "source": [
    "print('mu shape:', train_model.mu.get_shape())\n",
    "print('sigma shape:', train_model.sigma.get_shape())\n",
    "print('w shape:', train_model.w.get_shape())\n",
    "\n",
    "print('out shape:', train_model.out.get_shape())\n",
    "\n",
    "print('loss shape:', train_model.loss.get_shape())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0  | loss: 0.0127263879776\n",
      "100  | loss: 1.20739375353\n",
      "200  | loss: 1.10066717982\n",
      "300  | loss: 0.850288107395\n",
      "400  | loss: 0.651929777265\n",
      "500  | loss: 0.598655427098\n",
      "600  | loss: 0.560335657597\n",
      "700  | loss: 0.523335894346\n",
      "800  | loss: 0.485066242814\n",
      "900  | loss: 0.449415409565\n",
      "1000  | loss: 0.411708776057\n",
      "1100  | loss: 0.360139915347\n",
      "1200  | loss: 0.29437020272\n",
      "1300  | loss: 0.223771533519\n",
      "1400  | loss: 0.154679082185\n",
      "1500  | loss: 0.0965109656006\n",
      "1600  | loss: 0.0549155367166\n",
      "1700  | loss: 0.0236063866457\n",
      "1800  | loss: -0.0145678763546\n",
      "1900  | loss: -0.0819727937132\n",
      "2000  | loss: -0.191443995982\n",
      "2100  | loss: -0.339002245367\n",
      "2200  | loss: -0.51268802613\n",
      "2300  | loss: -0.693941006064\n",
      "2400  | loss: -0.842288567424\n",
      "2500  | loss: -0.932336855531\n",
      "2600  | loss: -0.981260842085\n",
      "2700  | loss: -1.00948995292\n",
      "2800  | loss: -1.02590925455\n",
      "2900  | loss: -1.03553029656\n",
      "3000  | loss: -1.04157194972\n",
      "3100  | loss: -1.04605837345\n",
      "3200  | loss: -1.04909473538\n",
      "3300  | loss: -1.05194606662\n",
      "3400  | loss: -1.05389161825\n",
      "3500  | loss: -1.0560163784\n",
      "3600  | loss: -1.05743619323\n",
      "3700  | loss: -1.05906661868\n",
      "3800  | loss: -1.06005476236\n",
      "3900  | loss: -1.06140472531\n",
      "4000  | loss: -1.06219060898\n",
      "4100  | loss: -1.06304368973\n",
      "4200  | loss: -1.06401746154\n",
      "4300  | loss: -1.06452438116\n",
      "4400  | loss: -1.06536564231\n",
      "4500  | loss: -1.06571970701\n",
      "4600  | loss: -1.06647113681\n",
      "4700  | loss: -1.06676548362\n",
      "4800  | loss: -1.06721468449\n",
      "4900  | loss: -1.0677867806\n",
      "5000  | loss: -1.06802026749\n",
      "5100  | loss: -1.06856617689\n",
      "5200  | loss: -1.06869198561\n",
      "5300  | loss: -1.06923437238\n",
      "5400  | loss: -1.06935314059\n",
      "5500  | loss: -1.06961639881\n",
      "5600  | loss: -1.07005433679\n",
      "5700  | loss: -1.07038246155\n",
      "5800  | loss: -1.07043508768\n",
      "5900  | loss: -1.07087452412\n",
      "6000  | loss: -1.07091437459\n",
      "6100  | loss: -1.07132606268\n",
      "6200  | loss: -1.07145857334\n",
      "6300  | loss: -1.07157099485\n",
      "6400  | loss: -1.07202410936\n",
      "6500  | loss: -1.0720267117\n",
      "6600  | loss: -1.07240911126\n",
      "6700  | loss: -1.07247996569\n",
      "6800  | loss: -1.07275327086\n",
      "6900  | loss: -1.07288175941\n",
      "7000  | loss: -1.07314254165\n",
      "7100  | loss: -1.07317652941\n",
      "7200  | loss: -1.07355078816\n",
      "7300  | loss: -1.07354230881\n",
      "7400  | loss: -1.07389115214\n",
      "7500  | loss: -1.07379972696\n",
      "7600  | loss: -1.07420926571\n",
      "7700  | loss: -1.07417498946\n",
      "7800  | loss: -1.07434044838\n",
      "7900  | loss: -1.0746219182\n",
      "8000  | loss: -1.07456871152\n",
      "8100  | loss: -1.07492871404\n",
      "8200  | loss: -1.07487744212\n",
      "8300  | loss: -1.07519296169\n",
      "8400  | loss: -1.07505138636\n",
      "8500  | loss: -1.07543941855\n",
      "8600  | loss: -1.07533607721\n",
      "8700  | loss: -1.07566605449\n",
      "8800  | loss: -1.0755837512\n",
      "8900  | loss: -1.07578265548\n",
      "9000  | loss: -1.07588878512\n",
      "9100  | loss: -1.0758702445\n",
      "9200  | loss: -1.07616069198\n",
      "9300  | loss: -1.07606729269\n",
      "9400  | loss: -1.07615551114\n",
      "9500  | loss: -1.07639886737\n",
      "9600  | loss: -1.0762905848\n",
      "9700  | loss: -1.0764058888\n",
      "9800  | loss: -1.07657041311\n",
      "9900  | loss: -1.07645378709\n",
      "function takes:  1394.3166773319244\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000 #1000\n",
    "n_logging = 100\n",
    "n_test_logg = 10\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print('Initialized')\n",
    "\n",
    "mean_loss= 0\n",
    "train_accuracy= 0\n",
    "\n",
    "t0 = time()\n",
    "for step in range(num_steps):   \n",
    "    \n",
    "    _, l = sess.run([optimizer, train_model.loss],feed_dict={train_model.inputs : np.expand_dims(data.train.x,1),\n",
    "                                                             train_model.labels : np.expand_dims(data.train.y,1)})\n",
    "    mean_loss += l    \n",
    "    \n",
    "    \n",
    "    if step%n_logging == 0:                \n",
    "        print(step, ' | loss:', mean_loss/n_logging)\n",
    "        mean_loss= 0\n",
    "        \n",
    "t1 = time()\n",
    "print('function takes: ', (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model for testing\n",
    "n_test= 100;\n",
    "test_model = gmm_model.setup(n_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "x_plot = np.linspace(-2, 2, n_test)\n",
    "\n",
    "[mu_out, sigma_out, w_out,] = sess.run([ test_model.mu, test_model.sigma, test_model.w ],\n",
    "                                         feed_dict= {test_model.inputs : np.expand_dims(x_plot, 1)})\n",
    "#print('mu:', mu_out, 'sigma:', sigma_out, 'w:', w_out)\n",
    "\n",
    "print(np.squeeze(mu_out).shape)\n",
    "print(x_plot.shape)\n",
    "\n",
    "# plot\n",
    "#plt.plot(x_plot, np.squeeze(mu_out), 'o')\n",
    "\n",
    "#plt.plot(x_plot, np.squeeze(mu_out) + np.squeeze(np.sqrt(sigma_out)), 'ro')\n",
    "#plt.plot(x_plot, np.squeeze(mu_out) - np.squeeze(np.sqrt(sigma_out)), 'ro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
